{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad8af9f5",
   "metadata": {},
   "source": [
    "## UNSW-NB15: Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a750033",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"./final_ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f09f1f",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2e3378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # for array\n",
    "import pandas as pd  # for csv files and dataframe\n",
    "import matplotlib.pyplot as plt  # for plotting\n",
    "import seaborn as sns  # plotting\n",
    "from scipy import stats\n",
    "from tqdm import tqdm  # Progress bar\n",
    "\n",
    "import pickle  # To load data int disk\n",
    "from prettytable import PrettyTable  # To print in tabular format\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler  # Standardizer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder  # One hot Encoder\n",
    "from scipy.sparse import csr_matrix  # For sparse matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Different Models\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier  # LR\n",
    "from sklearn.svm import LinearSVC  # SVM\n",
    "from sklearn.tree import DecisionTreeClassifier  #DT\n",
    "from sklearn.ensemble import RandomForestClassifier  # RF\n",
    "import xgboost as xgb  #XGB\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, make_scorer  # Scoring functions\n",
    "from sklearn.metrics import auc, f1_score, roc_curve, roc_auc_score  # Scoring fns\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV  # Cross validation\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a8cac3",
   "metadata": {},
   "source": [
    "## Loading files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0d16a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Test data\n",
    "x_train, y_train = pickle.load(open(file_path+'/final_train.pkl', 'rb'))\n",
    "x_test, y_test = pickle.load(open(file_path+'/final_test.pkl', 'rb'))\n",
    "\n",
    "# Dictionaries\n",
    "saved_dict = pickle.load(open(file_path+'/saved_dict.pkl', 'rb'))\n",
    "mode_dict = pickle.load(open(file_path+'/mode_dict.pkl', 'rb'))\n",
    "\n",
    "# Standard scaler\n",
    "scaler = pickle.load(open(file_path+'/scaler.pkl', 'rb'))\n",
    "\n",
    "# Onehot encoders\n",
    "ohe_proto = pickle.load(open(file_path+'/ohe_proto.pkl', 'rb'))\n",
    "ohe_service = pickle.load(open(file_path+'/ohe_service.pkl', 'rb'))\n",
    "ohe_state = pickle.load(open(file_path+'/ohe_state.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c70581ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the train data sparse matrix\n",
    "x_train_csr = csr_matrix(x_train.values)\n",
    "\n",
    "col = x_train.columns\n",
    "\n",
    "# Creating sparse dataframe with x_train sparse matrix\n",
    "x_train = pd.DataFrame.sparse.from_spmatrix(x_train_csr, columns=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "add52614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving it to disk to use later\n",
    "pickle.dump((x_train, y_train), open(file_path+'/train_sparse.pkl', 'wb'))\n",
    "\n",
    "# Loading sparse data\n",
    "x_train, y_train = pickle.load(open(file_path+'/train_sparse.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efc3667c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sttl</th>\n",
       "      <th>dttl</th>\n",
       "      <th>swin</th>\n",
       "      <th>trans_depth</th>\n",
       "      <th>res_bdy_len</th>\n",
       "      <th>stime</th>\n",
       "      <th>sintpkt</th>\n",
       "      <th>dintpkt</th>\n",
       "      <th>tcprtt</th>\n",
       "      <th>synack</th>\n",
       "      <th>...</th>\n",
       "      <th>state_INT</th>\n",
       "      <th>state_MAS</th>\n",
       "      <th>state_PAR</th>\n",
       "      <th>state_REQ</th>\n",
       "      <th>state_RST</th>\n",
       "      <th>state_TST</th>\n",
       "      <th>state_TXD</th>\n",
       "      <th>state_URH</th>\n",
       "      <th>state_URN</th>\n",
       "      <th>state_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.561444</td>\n",
       "      <td>-0.717760</td>\n",
       "      <td>-1.196045</td>\n",
       "      <td>-0.225343</td>\n",
       "      <td>-0.089113</td>\n",
       "      <td>-1.172764</td>\n",
       "      <td>-0.057567</td>\n",
       "      <td>-0.055099</td>\n",
       "      <td>-0.136439</td>\n",
       "      <td>-0.128893</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.037542</td>\n",
       "      <td>-0.717760</td>\n",
       "      <td>-1.196045</td>\n",
       "      <td>-0.225343</td>\n",
       "      <td>-0.089113</td>\n",
       "      <td>0.868469</td>\n",
       "      <td>-0.069616</td>\n",
       "      <td>-0.055099</td>\n",
       "      <td>-0.136439</td>\n",
       "      <td>-0.128893</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.426051</td>\n",
       "      <td>-0.041365</td>\n",
       "      <td>0.836096</td>\n",
       "      <td>-0.225343</td>\n",
       "      <td>-0.089113</td>\n",
       "      <td>-1.157401</td>\n",
       "      <td>-0.069485</td>\n",
       "      <td>-0.054857</td>\n",
       "      <td>-0.121383</td>\n",
       "      <td>-0.107394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.426051</td>\n",
       "      <td>-0.041365</td>\n",
       "      <td>0.836096</td>\n",
       "      <td>-0.225343</td>\n",
       "      <td>-0.089113</td>\n",
       "      <td>-1.136357</td>\n",
       "      <td>-0.063807</td>\n",
       "      <td>-0.044512</td>\n",
       "      <td>-0.120830</td>\n",
       "      <td>-0.107159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.426051</td>\n",
       "      <td>-0.041365</td>\n",
       "      <td>0.836096</td>\n",
       "      <td>-0.225343</td>\n",
       "      <td>-0.089113</td>\n",
       "      <td>-1.144197</td>\n",
       "      <td>-0.069180</td>\n",
       "      <td>-0.054358</td>\n",
       "      <td>-0.123351</td>\n",
       "      <td>-0.110421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sttl      dttl      swin  trans_depth  res_bdy_len     stime   sintpkt  \\\n",
       "0  2.561444 -0.717760 -1.196045    -0.225343    -0.089113 -1.172764 -0.057567   \n",
       "1 -0.037542 -0.717760 -1.196045    -0.225343    -0.089113  0.868469 -0.069616   \n",
       "2 -0.426051 -0.041365  0.836096    -0.225343    -0.089113 -1.157401 -0.069485   \n",
       "3 -0.426051 -0.041365  0.836096    -0.225343    -0.089113 -1.136357 -0.063807   \n",
       "4 -0.426051 -0.041365  0.836096    -0.225343    -0.089113 -1.144197 -0.069180   \n",
       "\n",
       "    dintpkt    tcprtt    synack  ...  state_INT  state_MAS  state_PAR  \\\n",
       "0 -0.055099 -0.136439 -0.128893  ...        1.0        0.0        0.0   \n",
       "1 -0.055099 -0.136439 -0.128893  ...        1.0        0.0        0.0   \n",
       "2 -0.054857 -0.121383 -0.107394  ...        0.0        0.0        0.0   \n",
       "3 -0.044512 -0.120830 -0.107159  ...        0.0        0.0        0.0   \n",
       "4 -0.054358 -0.123351 -0.110421  ...        0.0        0.0        0.0   \n",
       "\n",
       "   state_REQ  state_RST  state_TST  state_TXD  state_URH  state_URN  state_no  \n",
       "0        0.0        0.0        0.0        0.0        0.0        0.0       0.0  \n",
       "1        0.0        0.0        0.0        0.0        0.0        0.0       0.0  \n",
       "2        0.0        0.0        0.0        0.0        0.0        0.0       0.0  \n",
       "3        0.0        0.0        0.0        0.0        0.0        0.0       0.0  \n",
       "4        0.0        0.0        0.0        0.0        0.0        0.0       0.0  \n",
       "\n",
       "[5 rows x 197 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.sparse.to_dense().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b802b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1778032, 197), (1778032,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49be2c5",
   "metadata": {},
   "source": [
    "## Pipeline functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ece48a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------------------\n",
    "# Data Cleaning\n",
    "#------------------------------------------------------------------------------------------\n",
    "def clean_data(data):\n",
    "    '''\n",
    "    Cleans given raw data. Performs various cleaning, removes Null and wrong values.\n",
    "    Check for columns datatype and fix them.\n",
    "    '''\n",
    "    numerical_col = data.select_dtypes(include=np.number).columns  # All the numerical columns list\n",
    "    categorical_col = data.select_dtypes(exclude=np.number).columns  # All the categorical columns list\n",
    "    \n",
    "    # Cleaning the data\n",
    "    for col in data.columns:\n",
    "        val = mode_dict[col]  # Mode value of the column in train data\n",
    "        data[col] = data[col].fillna(value=val)\n",
    "        data[col] = data[col].replace(' ', value=val)\n",
    "        data[col] = data[col].apply(lambda x:\"None\" if x==\"-\" else x)\n",
    "\n",
    "        # Fixing binary columns\n",
    "        if col in saved_dict['binary_col']:\n",
    "            data[col] = np.where(data[col]>1, val, data[col])\n",
    "\n",
    "    # Fixing datatype of columns\n",
    "    bad_dtypes = list(set(categorical_col) - set(saved_dict['cat_col']))\n",
    "    for bad_col in bad_dtypes:\n",
    "        data[col] = data[col].astype(float)\n",
    "    \n",
    "    return data\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# Feature Engineering: Apply log1p\n",
    "#------------------------------------------------------------------------------------------\n",
    "def apply_log1p(data):\n",
    "    '''\n",
    "    Performs FE on the data. Apply log1p on the specified columns create new column and remove those original columns.\n",
    "    '''\n",
    "    for col in saved_dict['log1p_col']:\n",
    "        new_col = col + '_log1p'  # New col name\n",
    "        data[new_col] = data[col].apply(np.log1p)  # Creating new column on transformed data\n",
    "        data.drop(col, axis=1, inplace=True)  # Removing old columns\n",
    "    return data\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# Standardizing: Mean centering an d varience scaling\n",
    "#------------------------------------------------------------------------------------------\n",
    "def standardize(data):\n",
    "    '''\n",
    "    Stanardize the given data. Performs mean centering and varience scaling.\n",
    "    Using stanardscaler object trained on train data.\n",
    "    '''\n",
    "    data[saved_dict['num_col']] = scaler.transform(data[saved_dict['num_col']])\n",
    "    return data\n",
    "\n",
    "#------------------------------------------------------------------------------------------\n",
    "# Onehot encoding of categorical columns\n",
    "#------------------------------------------------------------------------------------------\n",
    "def ohencoding(data):\n",
    "    '''\n",
    "    Onehot encoding the categoricla columns.\n",
    "    Add the ohe columns with the data and removes categorical columns.\n",
    "    Using Onehotencoder objects trained on train data.\n",
    "    '''\n",
    "    # Onehot encoding cat col using onehotencoder objects\n",
    "    X = ohe_service.transform(data['service'].values.reshape(-1, 1))\n",
    "    Xm = ohe_proto.transform(data['proto'].values.reshape(-1, 1))\n",
    "    Xmm = ohe_state.transform(data['state'].values.reshape(-1, 1))\n",
    "    \n",
    "    # Adding encoding data to original data\n",
    "    data = pd.concat([data,\n",
    "                      pd.DataFrame(Xm.toarray(), columns=['proto_'+i for i in ohe_proto.categories_[0]]),\n",
    "                      pd.DataFrame(X.toarray(), columns=['service_'+i for i in ohe_service.categories_[0]]),\n",
    "                      pd.DataFrame(Xmm.toarray(), columns=['state_'+i for i in ohe_state.categories_[0]])],\n",
    "                      axis=1)\n",
    "    \n",
    "    # Removing cat columns\n",
    "    data.drop(['proto', 'service', 'state'], axis=1, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d9bce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_data(data, saved_dict=saved_dict, mode_dict=mode_dict):\n",
    "    '''\n",
    "    This functions takes raw input and convert that to model required output.\n",
    "    '''\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data.columns = saved_dict['columns']\n",
    "    \n",
    "    data['network_bytes'] = data['dbytes'] + data['sbytes']\n",
    "    \n",
    "    dropable_col = saved_dict['to_drop'] + saved_dict['corr_col']\n",
    "    data.drop(columns=dropable_col, inplace=True)\n",
    "    \n",
    "    data = clean_data(data)\n",
    "    data = apply_log1p(data)\n",
    "    data = standardize(data)\n",
    "    data = ohencoding(data)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d19091",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
